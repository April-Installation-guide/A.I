import { Client, GatewayIntentBits } from "discord.js";
import Groq from "groq-sdk";
import dotenv from 'dotenv';

// Importaci√≥n crucial con la nueva ruta
import { MANCY_CONFIG, SYSTEM_CONSTANTS } from './src/config/constants.js'; 

dotenv.config();

// =================================================================
// ========== ESTADO Y CONFIGURACI√ìN ==========
// =================================================================

if (!process.env.GROQ_API_KEY) {
    console.error("‚ùå ERROR: La variable GROQ_API_KEY no est√° definida.");
}

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

let discordClient = null;
export let botActive = false;
export let isStartingUp = false;
let startAttempts = 0;
let messageQueue = [];
let processingMessage = false;

// Cache simple para evitar procesamiento duplicado
const messageCache = new Map();
const CACHE_DURATION = 5000; // 5 segundos

// =================================================================
// ========== CONFIGURACI√ìN DE MODELOS ==========
// =================================================================

// Lista de modelos disponibles en Groq (priorizando Llama 3.1)
const AVAILABLE_MODELS = {
    // Llama 3.1 (recomendado - m√°s reciente y potente)
    'llama-3.1-70b-versatile': {
        name: 'llama-3.1-70b-versatile',
        displayName: 'Llama 3.1 70B Versatile',
        contextWindow: 131072,
        description: 'Modelo Llama 3.1 de 70B par√°metros, muy vers√°til'
    },
    'llama-3.1-8b-instant': {
        name: 'llama-3.1-8b-instant',
        displayName: 'Llama 3.1 8B Instant',
        contextWindow: 131072,
        description: 'Modelo Llama 3.1 de 8B par√°metros, r√°pido'
    },
    'llama3-70b-8192': {
        name: 'llama3-70b-8192',
        displayName: 'Llama 3 70B',
        contextWindow: 8192,
        description: 'Modelo Llama 3 de 70B par√°metros'
    },
    'llama3-8b-8192': {
        name: 'llama3-8b-8192',
        displayName: 'Llama 3 8B',
        contextWindow: 8192,
        description: 'Modelo Llama 3 de 8B par√°metros, r√°pido'
    },
    // Mixtral (modelo anterior)
    'mixtral-8x7b-32768': {
        name: 'mixtral-8x7b-32768',
        displayName: 'Mixtral 8x7B',
        contextWindow: 32768,
        description: 'Modelo Mixtral de expertos'
    }
};

// Selecci√≥n del modelo (puedes cambiarlo aqu√≠)
const SELECTED_MODEL = AVAILABLE_MODELS['llama-3.1-70b-versatile']; // Cambiado a Llama 3.1
const MODEL_TEMPERATURE = 0.7; // Ajustable seg√∫n necesidad
const MODEL_MAX_TOKENS = 1024; // M√°ximo de tokens por respuesta

// =================================================================
// ========== FUNCIONES AUXILIARES MEJORADAS ==========
// =================================================================

/**
 * Extrae JSON de un string que pueda contener texto adicional
 */
function extractJSONFromText(text) {
    if (!text) return null;
    
    // Intentar parsear directamente
    try {
        return JSON.parse(text.trim());
    } catch {
        // Buscar objeto JSON en el texto
        const jsonMatch = text.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
            try {
                return JSON.parse(jsonMatch[0]);
            } catch {
                // Intentar limpiar el JSON
                const cleaned = jsonMatch[0]
                    .replace(/```json\s*/g, '')
                    .replace(/```\s*/g, '')
                    .trim();
                try {
                    return JSON.parse(cleaned);
                } catch (e) {
                    console.log("‚ùå No se pudo limpiar el JSON:", e.message);
                }
            }
        }
    }
    return null;
}

/**
 * Valida que el JSON tenga la estructura esperada
 */
function validateResponseStructure(response) {
    if (!response || typeof response !== 'object') {
        return false;
    }
    
    // Verificar estructura b√°sica esperada
    if (!response.respuesta_discord || typeof response.respuesta_discord !== 'string') {
        return false;
    }
    
    // Validar longitud m√°xima para Discord
    if (response.respuesta_discord.length > 2000) {
        response.respuesta_discord = response.respuesta_discord.substring(0, 1997) + "...";
    }
    
    return true;
}

/**
 * Funci√≥n para listar modelos disponibles (√∫til para debugging)
 */
export async function listAvailableModels() {
    try {
        // Nota: Groq no tiene endpoint p√∫blico para listar modelos
        // pero podemos intentar usar uno para verificar disponibilidad
        console.log("üìã Modelos configurados disponibles:");
        console.log("======================================");
        
        Object.values(AVAILABLE_MODELS).forEach((model, index) => {
            const isSelected = model.name === SELECTED_MODEL.name;
            console.log(`${isSelected ? '‚úÖ' : '  '} ${index + 1}. ${model.displayName}`);
            console.log(`     ID: ${model.name}`);
            console.log(`     Contexto: ${model.contextWindow} tokens`);
            console.log(`     Descripci√≥n: ${model.description}`);
            console.log(`     ${isSelected ? '‚Üê ACTUALMENTE SELECCIONADO' : ''}`);
            console.log();
        });
        
        return {
            selected: SELECTED_MODEL,
            available: AVAILABLE_MODELS,
            count: Object.keys(AVAILABLE_MODELS).length
        };
    } catch (error) {
        console.error("‚ùå Error listando modelos:", error);
        return null;
    }
}

// =================================================================
// ========== LLAMADA A GROQ MEJORADA CON LLAMA 3.1 ==========
// =================================================================

async function getGroqResponse(systemPrompt, userPrompt, temperature, maxTokens) {
    const jsonSchema = MANCY_CONFIG.OUTPUT_SCHEMA;
    
    // System prompt optimizado para Llama 3.1
    const groqSystemPrompt = `${systemPrompt}\n\n
IMPORTANTE: Eres el modelo ${SELECTED_MODEL.displayName}. 
Debes responder √öNICAMENTE con un objeto JSON v√°lido.

REGLAS ESTRICTAS:
1. NO incluyas ning√∫n texto fuera del JSON
2. NO uses markdown, code blocks o comillas triples
3. El JSON DEBE seguir exactamente este esquema:
${JSON.stringify(jsonSchema, null, 2)}

EJEMPLO DE RESPUESTA CORRECTA:
${JSON.stringify(MANCY_CONFIG.FALLBACK_RESPONSE, null, 2)}

Tu respuesta debe comenzar con { y terminar con }.
No expliques, no comentes, solo JSON.`;

    try {
        console.log(`ü§ñ Usando modelo: ${SELECTED_MODEL.displayName} (${SELECTED_MODEL.name})`);
        
        // Timeout para la llamada a la API
        const timeoutPromise = new Promise((_, reject) => 
            setTimeout(() => reject(new Error(`Timeout de API excedido (30s) con modelo ${SELECTED_MODEL.name}`)), 30000)
        );

        const apiPromise = groq.chat.completions.create({
            messages: [
                { 
                    role: "system", 
                    content: groqSystemPrompt 
                },
                { 
                    role: "user", 
                    content: userPrompt 
                }
            ],
            model: SELECTED_MODEL.name, // Usamos el modelo seleccionado
            temperature: temperature || MODEL_TEMPERATURE,
            max_tokens: maxTokens || MODEL_MAX_TOKENS,
            response_format: { type: "json_object" },  // Forzar modo JSON
            stream: false
        });

        // Ejecutar con timeout
        const chatCompletion = await Promise.race([apiPromise, timeoutPromise]);
        
        if (!chatCompletion.choices || !chatCompletion.choices[0]) {
            throw new Error("Respuesta de API vac√≠a o inv√°lida");
        }

        const rawContent = chatCompletion.choices[0].message?.content?.trim();
        
        if (!rawContent) {
            console.error("‚ùå Contenido vac√≠o recibido de Groq");
            return MANCY_CONFIG.FALLBACK_RESPONSE;
        }

        // DEBUG: Log para ver qu√© est√° recibiendo
        if (process.env.NODE_ENV === 'development' || process.env.DEBUG_MODEL === 'true') {
            console.log(`üì• Raw content (primeros 300 chars):`, rawContent.substring(0, 300));
            console.log(`üìä Longitud: ${rawContent.length} caracteres`);
        }

        // Intentar extraer y validar JSON
        const parsedResponse = extractJSONFromText(rawContent);
        
        if (!parsedResponse) {
            console.error("‚ùå No se pudo extraer JSON v√°lido del modelo");
            console.log("üìÑ Contenido recibido (inicio):", rawContent.substring(0, 500));
            return MANCY_CONFIG.FALLBACK_RESPONSE;
        }

        // Validar estructura
        if (!validateResponseStructure(parsedResponse)) {
            console.error("‚ùå Estructura JSON inv√°lida del modelo:", Object.keys(parsedResponse));
            return MANCY_CONFIG.FALLBACK_RESPONSE;
        }

        // Sanitizar respuesta para Discord
        parsedResponse.respuesta_discord = parsedResponse.respuesta_discord
            .replace(/[\u0000-\u001F\u007F-\u009F]/g, '') // Remover caracteres de control
            .replace(/\s+/g, ' ') // Normalizar espacios
            .trim();

        // Asegurar que no est√© vac√≠o
        if (!parsedResponse.respuesta_discord || parsedResponse.respuesta_discord.length === 0) {
            parsedResponse.respuesta_discord = MANCY_CONFIG.FALLBACK_RESPONSE.respuesta_discord;
        }

        console.log(`‚úÖ Respuesta procesada correctamente (${parsedResponse.respuesta_discord.length} chars)`);
        return parsedResponse;

    } catch (error) {
        console.error("‚ùå Error en getGroqResponse:", {
            message: error.message,
            model: SELECTED_MODEL.name,
            type: error.constructor.name
        });
        
        // Intentar con un modelo alternativo si el principal falla
        if (error.message.includes('model') || error.message.includes('not found')) {
            console.log("üîÑ Intentando con modelo alternativo...");
            // Podr√≠as implementar l√≥gica de fallback a otro modelo aqu√≠
        }
        
        return {
            ...MANCY_CONFIG.FALLBACK_RESPONSE,
            respuesta_discord: `Error del modelo ${SELECTED_MODEL.displayName}: ${error.message}. Int√©ntalo de nuevo.`
        };
    }
}

// =================================================================
// ========== L√ìGICA DE INICIO DEL BOT MEJORADA ==========
// =================================================================

export function initializeAndStartBot() {
    if (isStartingUp) {
        console.log("‚ö†Ô∏è Ya hay un inicio en proceso...");
        return;
    }

    if (discordClient) {
        discordClient.destroy();
        discordClient = null;
        botActive = false;
    }
    
    discordClient = new Client({
        intents: [
            GatewayIntentBits.Guilds, 
            GatewayIntentBits.GuildMessages, 
            GatewayIntentBits.MessageContent,
            GatewayIntentBits.DirectMessages
        ]
    });
    
    // Mostrar informaci√≥n del modelo al iniciar
    console.log(`üöÄ Iniciando bot con modelo: ${SELECTED_MODEL.displayName}`);
    console.log(`   ID: ${SELECTED_MODEL.name}`);
    console.log(`   Context Window: ${SELECTED_MODEL.contextWindow} tokens`);
    
    startDiscordBot(); 
}

async function startDiscordBot() {
    if (!process.env.DISCORD_TOKEN) { 
        console.error("‚ùå ERROR: DISCORD_TOKEN no est√° definido."); 
        isStartingUp = false; 
        return; 
    }
    
    if (startAttempts >= SYSTEM_CONSTANTS.MAX_START_ATTEMPTS) { 
        console.error("‚ùå Error: M√°ximo de intentos de inicio alcanzado."); 
        isStartingUp = false; 
        return; 
    }
    
    isStartingUp = true;
    startAttempts++;

    try {
        await discordClient.login(process.env.DISCORD_TOKEN);
        
        discordClient.once('ready', () => {
            console.log(`======================================`);
            console.log(`ü§ñ Bot de Discord conectado como ${discordClient.user.tag}`);
            console.log(`üìä Modelo: ${SELECTED_MODEL.displayName}`);
            console.log(`üåê Servidores: ${discordClient.guilds.cache.size}`);
            console.log(`üöÄ Estado: LISTO`);
            console.log(`======================================`);
            
            botActive = true;
            isStartingUp = false;
            startAttempts = 0;
        });
        
        // Manejo de errores de conexi√≥n
        discordClient.on('error', (error) => {
            console.error("‚ùå Error en cliente de Discord:", error);
            if (botActive) {
                botActive = false;
                setTimeout(initializeAndStartBot, 10000);
            }
        });
        
        // Reconexi√≥n autom√°tica
        discordClient.on('disconnect', () => {
            console.log("üîå Bot desconectado, intentando reconectar...");
            botActive = false;
            setTimeout(initializeAndStartBot, 5000);
        });

        discordClient.on('messageCreate', handleDiscordMessage);

    } catch (error) {
        console.error(`‚ùå Intento ${startAttempts} fallido. Reintentando en 5s...`, error.message);
        isStartingUp = false;
        
        // Delay exponencial para reintentos
        const delay = Math.min(5000 * Math.pow(1.5, startAttempts - 1), 30000);
        setTimeout(startDiscordBot, delay);
    }
}

// =================================================================
// ========== MANEJADOR DE MENSAJES MEJORADO ==========
// =================================================================

async function handleDiscordMessage(message) {
    // Ignorar bots
    if (message.author.bot) return;
    
    // Verificar si es DM o menci√≥n
    const isDirectMessage = message.channel.type === 1; 
    const isMention = message.mentions.users.has(discordClient.user.id);
    
    if (!isDirectMessage && !isMention) return;
    
    // Limpiar mensaje
    let userMessage = message.content.replace(new RegExp(`<@!?${discordClient.user.id}>`), '').trim();
    if (!userMessage) {
        // Responder a mensajes vac√≠os
        await message.reply("¬øS√≠? ¬øEn qu√© puedo ayudarte?");
        return;
    }
    
    // Verificar cach√© para evitar procesamiento duplicado
    const cacheKey = `${message.author.id}-${userMessage.substring(0, 50)}`;
    if (messageCache.has(cacheKey)) {
        console.log("‚ö†Ô∏è Mensaje duplicado detectado, ignorando...");
        return;
    }
    
    messageCache.set(cacheKey, true);
    setTimeout(() => messageCache.delete(cacheKey), CACHE_DURATION);
    
    try {
        await message.channel.sendTyping();
        
        // 1. Usar identidad base como System Prompt
        const systemPrompt = MANCY_CONFIG.IDENTITY;
        
        // 2. Agregar contexto b√°sico
        const enhancedPrompt = `${userMessage}\n\nContexto: ${isDirectMessage ? 'Mensaje directo' : 'Mencionado en canal p√∫blico'}. Usuario: ${message.author.username}`;
        
        console.log(`üì® Procesando mensaje de ${message.author.tag}: "${userMessage.substring(0, 100)}..."`);
        
        // 3. Llamar a la IA con timeout
        const timeoutPromise = new Promise((_, reject) => 
            setTimeout(() => reject(new Error(`Timeout procesando con ${SELECTED_MODEL.displayName}`)), 25000)
        );
        
        const aiPromise = getGroqResponse(
            systemPrompt, 
            enhancedPrompt, 
            MODEL_TEMPERATURE, 
            MODEL_MAX_TOKENS
        );
        
        const mancyResponseObject = await Promise.race([aiPromise, timeoutPromise]);
        
        // 4. Enviar respuesta
        await message.reply({
            content: mancyResponseObject.respuesta_discord,
            allowedMentions: { repliedUser: false }
        });

        console.log(`‚úÖ Respuesta enviada a ${message.author.tag}`);

    } catch (error) {
        console.error(`‚ùå Error procesando mensaje de ${message.author.tag}:`, error.message);
        
        // Respuesta de error amigable
        const errorResponses = [
            `¬°Ups! Mi cerebro (${SELECTED_MODEL.displayName}) se ha atascado. ¬øPodr√≠as intentarlo de nuevo?`,
            `Error de procesamiento en ${SELECTED_MODEL.displayName}. Reiniciando sinapsis...`,
            `Parece que hay interferencia en mi matriz de pensamiento. Intenta de nuevo.`,
            `¬°Vaya! Mi modelo ${SELECTED_MODEL.displayName} necesita un momento. ¬øRepites?`
        ];
        
        const randomError = errorResponses[Math.floor(Math.random() * errorResponses.length)];
        
        try {
            await message.reply(randomError);
        } catch (replyError) {
            console.error("‚ùå Error al enviar mensaje de error:", replyError.message);
        }
    }
}

// =================================================================
// ========== UTILITIES MEJORADAS ==========
// =================================================================

export function getBotStatus() {
    return {
        bot_active: botActive,
        starting_up: isStartingUp,
        startAttempts: startAttempts,
        maxAttempts: SYSTEM_CONSTANTS.MAX_START_ATTEMPTS,
        model: SELECTED_MODEL,
        capabilities: MANCY_CONFIG.CAPABILITIES,
        version: MANCY_CONFIG.VERSION,
        uptime: botActive ? process.uptime() : 0,
        guilds: discordClient?.guilds?.cache?.size || 0,
        memory_usage: process.memoryUsage(),
        cache_size: messageCache.size
    };
}

export function forceRestartBot() {
    console.log("üîÑ Reinicio forzado solicitado...");
    startAttempts = 0;
    initializeAndStartBot();
}

export function changeModel(modelKey) {
    if (AVAILABLE_MODELS[modelKey]) {
        console.log(`üîÑ Cambiando modelo de ${SELECTED_MODEL.name} a ${AVAILABLE_MODELS[modelKey].name}`);
        SELECTED_MODEL = AVAILABLE_MODELS[modelKey];
        return { success: true, newModel: SELECTED_MODEL };
    } else {
        console.error(`‚ùå Modelo no disponible: ${modelKey}`);
        return { success: false, available: Object.keys(AAVAILABLE_MODELS) };
    }
}

export function getMessageQueue() {
    return {
        queue_length: messageQueue.length,
        processing: processingMessage,
        cache_size: messageCache.size
    };
}

// Funci√≥n para probar el modelo
export async function testModelConnection() {
    try {
        console.log("üß™ Probando conexi√≥n con modelo...");
        const testPrompt = "Responde con un JSON simple: {\"test\": \"ok\"}";
        const response = await getGroqResponse("Eres un asistente √∫til.", testPrompt, 0.1, 50);
        console.log("‚úÖ Conexi√≥n exitosa con modelo:", response);
        return { success: true, response };
    } catch (error) {
        console.error("‚ùå Error probando modelo:", error);
        return { success: false, error: error.message };
    }
}

// Inicio autom√°tico si se ejecuta directamente
if (import.meta.url === `file://${process.argv[1]}`) {
    initializeAndStartBot();
    
    // Opcional: Probar conexi√≥n al iniciar
    setTimeout(async () => {
        if (botActive) {
            await testModelConnection();
        }
    }, 5000);
}
