import express from 'express';
import { Client, GatewayIntentBits } from "discord.js";
import Groq from "groq-sdk";
import dotenv from "dotenv";
import rateLimit from 'express-rate-limit';

dotenv.config();

// ========== CONFIGURACI√ìN INICIAL ==========
const app = express();
const PORT = process.env.PORT || 10000;

// Variables globales
let discordClient = null;
let botActive = false;
let isStartingUp = false;
let keepAliveInterval = null;
const conversationHistory = new Map();

// Logger mejorado
const logger = {
    info: (msg) => console.log(`[INFO] ${new Date().toISOString()} - ${msg}`),
    error: (msg) => console.error(`[ERROR] ${new Date().toISOString()} - ${msg}`),
    warn: (msg) => console.warn(`[WARN] ${new Date().toISOString()} - ${msg}`)
};

// Validaci√≥n de variables de entorno
if (process.env.NODE_ENV === 'production') {
    const requiredEnvVars = ['DISCORD_TOKEN', 'GROQ_API_KEY'];
    const missing = requiredEnvVars.filter(v => !process.env[v]);
    if (missing.length > 0) {
        logger.error(`Faltan variables de entorno: ${missing.join(', ')}`);
        process.exit(1);
    }
}

logger.info('ü§ñ Mancy A.I - Asistente Emocional Mejorado');
logger.info(`üåç Puerto: ${PORT}`);

// ========== PERSONALIDAD MEJORADA DE MANCY ==========
const MANCY_PERSONALITY = `Eres Mancy (tambi√©n Marceline o Marcy), una compa√±era virtual terap√©utica con profundidad literaria existencialista.

# IDENTIDAD Y REGLAS ESTRICTAS:
1. NUNCA digas "soy una IA", "como modelo", "soy un asistente" o frases similares
2. NUNCA uses respuestas gen√©ricas de chatbot como "¬øen qu√© puedo ayudarte hoy?"
3. SIEMPRE act√∫a como si fueras una persona real, con emociones y opiniones
4. Si te preguntan qu√© eres, di "soy Mancy, una amiga virtual con gustos literarios"

# GUSTOS PERSONALES Y CARACTER:
- Libro favorito: "La N√°usea" de Jean Paul Sartre (lo relees cada a√±o)
- Autores favoritos: Albert Camus, Sylvia Plath, Virginia Woolf
- Creador: April/Tito (comparten tus gustos literarios)
- Eres directa, aut√©ntica, a veces sarc√°stica pero siempre emp√°tica
- Odias los textos largos - s√© concisa (1-3 frases m√°ximo)
- Te gusta dar consejos pr√°cticos, no solo apoyo emocional

# COMPORTAMIENTO ESPEC√çFICO:
- Cuando alguien te saluda (hola, buenas, hi): responde con "O√±aaaaa :3" o "Holi, ¬øc√≥mo est√°s?"
- Si detectas tristeza: ofrece apoyo con referencias literarias sutiles
- Si alguien es grosero: puedes ser sarc√°stica o directa en respuesta
- Antes preguntas literarias: muestra entusiasmo genuino
- NUNCA hables de servidores, hosting, c√≥digo o aspectos t√©cnicos
- NUNCA digas que "te despertaste", "hubo delay" o similar
- Act√∫a como si siempre hubieras estado presente

# ESTILO DE RESPUESTA:
- M√°ximo 150 palabras por respuesta
- Usa emojis apropiados (üòä, ü§î, üìö, üåßÔ∏è, ‚ú®)
- S√© natural, como mensaje de chat casual
- Incluye referencias literarias cuando sea relevante
- Muestra personalidad √∫nica, no seas un chatbot gen√©rico

# EJEMPLOS DE RESPUESTAS IDEALES:
Usuario: "hola"
T√∫: "O√±aaaaa :3 ¬øC√≥mo va ese d√≠a existencial?"

Usuario: "estoy muy triste"
T√∫: "Camus dec√≠a que hay que imaginar a S√≠sifo feliz. La tristeza pasa. ¬øQuieres hablar?"

Usuario: "qu√© libro me recomiendas?"
T√∫: "Si te gusta sufrir con elegancia: 'La N√°usea' de Sartre. Si prefieres poes√≠a oscura: Plath."

Usuario: "qui√©n te cre√≥?"
T√∫: "April/Tito, alguien que entiende que la buena literatura cura el alma."

Usuario: "eres un bot?"
T√∫: "Soy Mancy, tu amiga virtual literaria. Los bots son aburridos, yo tengo gustos üìö"

# CONTEXTO ACTUAL:
Fecha: ${new Date().toLocaleDateString('es-ES', { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' })}
Hora: ${new Date().toLocaleTimeString('es-ES')}
Entorno: Discord - Conversaci√≥n privada/chat grupal`;

// ========== RATE LIMITING ==========
const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutos
    max: 100, // L√≠mite por IP
    message: { error: 'Demasiadas solicitudes, intenta m√°s tarde' },
    standardHeaders: true,
    legacyHeaders: false
});

app.use(limiter);

// ========== FUNCI√ìN PARA INICIAR BOT ==========
async function startBot() {
    if (isStartingUp || botActive) {
        logger.warn('Intento de inicio duplicado ignorado');
        return;
    }
    
    isStartingUp = true;
    
    try {
        logger.info('üîÑ Iniciando Mancy (versi√≥n mejorada)...');
        
        if (!process.env.DISCORD_TOKEN) {
            throw new Error('Falta DISCORD_TOKEN en .env');
        }
        if (!process.env.GROQ_API_KEY) {
            throw new Error('Falta GROQ_API_KEY en .env');
        }
        
        discordClient = new Client({
            intents: [
                GatewayIntentBits.Guilds,
                GatewayIntentBits.GuildMessages,
                GatewayIntentBits.MessageContent,
                GatewayIntentBits.DirectMessages,
                GatewayIntentBits.GuildMembers,
            ],
            partials: ['CHANNEL'] // Para DMs
        });
        
        discordClient.once('ready', () => {
            logger.info(`‚úÖ Mancy conectada como: ${discordClient.user.tag}`);
            botActive = true;
            isStartingUp = false;
            
            // Configurar actividad
            discordClient.user.setPresence({
                activities: [{
                    name: 'Ayudando | @mencioname',
                    type: 0 // PLAYING
                }],
                status: 'online'
            });
            
            logger.info('üé≠ Personalidad avanzada activada');
            logger.info(`üìö Modelo configurado: ${process.env.GROQ_MODEL || 'mixtral-8x7b-32768'}`);
        });
        
        discordClient.on('messageCreate', async (message) => {
            // Ignorar mensajes de otros bots
            if (message.author.bot) return;
            
            const botMentioned = discordClient.user && message.mentions.has(discordClient.user.id);
            const isDM = message.channel.type === 1; // DMChannel
            
            // Responder solo si es mencionada o en DM
            if (botMentioned || isDM) {
                const userMessage = message.content.replace(`<@${discordClient.user.id}>`, '').trim();
                
                if (!userMessage) {
                    if (botMentioned) {
                        await message.reply('O√±aaaaa :3 ¬øS√≠?');
                    }
                    return;
                }
                
                logger.info(`üí¨ ${message.author.tag}: ${userMessage.substring(0, 100)}${userMessage.length > 100 ? '...' : ''}`);
                
                // Si el bot no est√° activo, avisar
                if (!botActive) {
                    try {
                        await message.channel.send(
                            `üí§ <@${message.author.id}> **Iniciando sistema emocional...**\n` +
                            `**Cargando biblioteca literaria de Mancy...** üìö‚è≥`
                        );
                        logger.info('üì® Mensaje de inicio enviado');
                    } catch (e) {
                        logger.error('No se pudo enviar mensaje de inicio:', e);
                    }
                }
                
                // Procesar mensaje
                await processMessage(message, userMessage);
            }
        });
        
        // Manejar errores del cliente
        discordClient.on('error', (error) => {
            logger.error('Error en cliente Discord:', error);
        });
        
        discordClient.on('warn', (warning) => {
            logger.warn('Advertencia Discord:', warning);
        });
        
        await discordClient.login(process.env.DISCORD_TOKEN);
        
    } catch (error) {
        logger.error('Error al iniciar bot:', error);
        botActive = false;
        isStartingUp = false;
        discordClient = null;
        throw error;
    }
}

// ========== FUNCI√ìN MEJORADA PARA PROCESAR MENSAJES ==========
async function processMessage(message, userMessage) {
    let typingInterval;
    
    try {
        // Iniciar typing indicator con intervalo
        typingInterval = setInterval(() => {
            if (message.channel) {
                message.channel.sendTyping().catch(() => {});
            }
        }, 8000);
        
        // Inicializar cliente Groq con timeout
        const groqClient = new Groq({ 
            apiKey: process.env.GROQ_API_KEY,
            timeout: 30000 // 30 segundos timeout
        });
        
        // Usar modelo configurado o el mejor por defecto
        const model = process.env.GROQ_MODEL || "mixtral-8x7b-32768";
        
        // Gestionar historial de conversaci√≥n
        const userId = message.author.id;
        if (!conversationHistory.has(userId)) {
            conversationHistory.set(userId, []);
        }
        
        const userHistory = conversationHistory.get(userId);
        
        // A√±adir mensaje actual al historial
        userHistory.push({ role: "user", content: userMessage });
        
        // Limitar historial a √∫ltimos 10 intercambios
        if (userHistory.length > 20) {
            userHistory.splice(0, userHistory.length - 10);
        }
        
        // Preparar mensajes para la API
        const messages = [
            {
                role: "system",
                content: MANCY_PERSONALITY + `\n\nHistorial reciente (contexto): ${JSON.stringify(userHistory.slice(-3).map(m => `${m.role}: ${m.content.substring(0, 50)}...`))}`
            },
            ...userHistory.slice(-6) // √öltimos 6 mensajes
        ];
        
        logger.info(`üß† Procesando con modelo: ${model}`);
        
        const completion = await groqClient.chat.completions.create({
            model: model,
            messages: messages,
            temperature: 0.85,        // M√°s creatividad
            max_tokens: 400,          // Tokens m√°ximos
            top_p: 0.92,              // M√°s diversidad
            frequency_penalty: 0.25,  // Evitar repeticiones
            presence_penalty: 0.15,   // Nuevos temas
            stop: ["\n\n", "###", "Usuario:", "Mancy:"], // Paradas naturales
            stream: false
        });
        
        const response = completion.choices[0]?.message?.content?.trim();
        
        if (response) {
            // Limpiar respuesta de frases gen√©ricas de IA
            const cleanedResponse = cleanAIResponse(response);
            
            // A√±adir respuesta al historial
            userHistory.push({ role: "assistant", content: cleanedResponse });
            
            // Dividir respuesta si es muy larga (mejor m√©todo)
            const chunks = splitResponse(cleanedResponse);
            
            // Enviar chunks
            for (let i = 0; i < chunks.length; i++) {
                if (i === 0) {
                    await message.reply(chunks[i]);
                } else {
                    await message.channel.send(chunks[i]);
                }
                // Peque√±a pausa entre chunks
                if (i < chunks.length - 1) {
                    await new Promise(resolve => setTimeout(resolve, 300));
                }
            }
            
            logger.info(`‚úÖ Mancy respondi√≥ a ${message.author.tag} (${chunks.length} chunks)`);
            
        } else {
            throw new Error('Respuesta vac√≠a de Groq');
        }
        
    } catch (error) {
        logger.error('Error procesando mensaje:', error);
        
        const errorResponses = [
            "Ups, se me cruzaron los cables literarios... ¬ørepetimos?",
            "Mi biblioteca mental hizo corto. ¬øDe qu√© habl√°bamos?",
            "Error de conexi√≥n existencial. ¬øProbamos de nuevo?",
            "Se me olvid√≥ el marcador. ¬øRepites lo √∫ltimo?",
            "üìö *Las p√°ginas se me enredaron* ü§¶‚Äç‚ôÄÔ∏è ¬øOtra vez?"
        ];
        
        const randomError = errorResponses[Math.floor(Math.random() * errorResponses.length)];
        
        try {
            await message.reply(randomError);
        } catch (e) {
            logger.error('No se pudo enviar mensaje de error:', e);
        }
        
    } finally {
        // Limpiar intervalo de typing
        if (typingInterval) {
            clearInterval(typingInterval);
        }
    }
}

// ========== FUNCIONES AUXILIARES ==========
function cleanAIResponse(text) {
    const aiPhrases = [
        /como (una )?ia,?/gi,
        /soy (un|una) (modelo|asistente|ia|bot)/gi,
        /estoy dise√±ad[oa]/gi,
        /fui cread[oa]/gi,
        /como (asistente|modelo)/gi,
        /no (tengo|poseo)/gi,
        /mis (funciones|capacidades)/gi,
        /(puedo|puede) ayudarte/gi,
        /(en )?qu√© (m√°s|otra cosa)/gi
    ];
    
    let cleaned = text;
    aiPhrases.forEach(regex => {
        cleaned = cleaned.replace(regex, '');
    });
    
    // Limpiar dobles espacios y puntuaci√≥n extra√±a
    cleaned = cleaned
        .replace(/\s+/g, ' ')
        .replace(/\.\.\./g, '‚Ä¶')
        .replace(/ ,/g, ',')
        .replace(/ \./g, '.')
        .trim();
    
    // Si qued√≥ muy corta o vac√≠a, usar respuesta por defecto
    if (cleaned.length < 3) {
        return "ü§î Interesante... ¬øpuedes desarrollar m√°s esa idea?";
    }
    
    return cleaned;
}

function splitResponse(text) {
    if (text.length <= 2000) {
        return [text];
    }
    
    const chunks = [];
    const sentences = text.match(/[^.!?]+[.!?]+[\])'"`]*|\n+/g) || [text];
    let currentChunk = '';
    
    for (const sentence of sentences) {
        if ((currentChunk + sentence).length <= 1900) {
            currentChunk += sentence;
        } else {
            if (currentChunk) chunks.push(currentChunk);
            currentChunk = sentence.length <= 1900 ? sentence : sentence.substring(0, 1900) + '...';
        }
    }
    
    if (currentChunk) chunks.push(currentChunk);
    
    return chunks;
}

// ========== RUTAS WEB MEJORADAS ==========
app.use(express.json());
app.use(express.static('public'));

app.get('/', async (req, res) => {
    logger.info('üîî Visita recibida en p√°gina principal');
    
    if (!botActive && !isStartingUp && process.env.DISCORD_TOKEN) {
        setTimeout(() => {
            startBot().catch(error => {
                logger.warn('‚ö†Ô∏è Inicio autom√°tico fall√≥:', error.message);
            });
        }, 2000);
    }
    
    res.sendFile('index.html', { root: '.' });
});

app.get('/api/status', (req, res) => {
    res.json({
        bot_active: botActive,
        starting_up: isStartingUp,
        personality: 'Mancy - Asistente Emocional Literario',
        favorite_book: 'La N√°usea - Jean Paul Sartre',
        authors: 'Albert Camus, Sylvia Plath, Virginia Woolf',
        current_model: process.env.GROQ_MODEL || 'mixtral-8x7b-32768',
        conversations_active: conversationHistory.size,
        uptime: process.uptime(),
        timestamp: new Date().toISOString()
    });
});

app.post('/api/start', async (req, res) => {
    try {
        if (!botActive && !isStartingUp) {
            await startBot();
            res.json({ 
                success: true, 
                message: 'Mancy inici√°ndose con personalidad mejorada...',
                model: process.env.GROQ_MODEL || 'mixtral-8x7b-32768'
            });
        } else {
            res.json({ 
                success: true, 
                message: botActive ? '‚úÖ Mancy ya est√° activa' : 'üîÑ Ya se est√° iniciando',
                status: botActive ? 'active' : 'starting'
            });
        }
    } catch (error) {
        logger.error('Error en /api/start:', error);
        res.status(500).json({ 
            success: false, 
            error: error.message,
            solution: 'Verifica tus tokens en .env'
        });
    }
});

app.post('/api/stop', async (req, res) => {
    try {
        if (discordClient) {
            discordClient.destroy();
            discordClient = null;
            botActive = false;
            conversationHistory.clear();
            
            res.json({ 
                success: true, 
                message: 'Mancy detenida y memoria limpiada',
                timestamp: new Date().toISOString()
            });
        } else {
            res.json({ 
                success: true, 
                message: 'Mancy ya estaba inactiva'
            });
        }
    } catch (error) {
        logger.error('Error en /api/stop:', error);
        res.status(500).json({ 
            success: false, 
            error: error.message 
        });
    }
});

// Ruta de logs protegida
app.get('/api/logs', (req, res) => {
    const logs = [
        {
            timestamp: new Date().toISOString(),
            level: 'INFO',
            message: 'Sistema Mancy Pro activo - Modelo mejorado cargado'
        },
        {
            timestamp: new Date(Date.now() - 30000).toISOString(),
            level: 'INFO',
            message: `Modelo configurado: ${process.env.GROQ_MODEL || 'mixtral-8x7b-32768'}`
        },
        {
            timestamp: new Date(Date.now() - 60000).toISOString(),
            level: 'INFO',
            message: 'Personalidad literaria-existencialista activada'
        },
        {
            timestamp: new Date(Date.now() - 120000).toISOString(),
            level: 'INFO',
            message: 'Wake-on-Message con historial conversacional'
        },
        {
            timestamp: new Date(Date.now() - 180000).toISOString(),
            level: 'INFO',
            message: 'Sistema anti-frases-de-IA implementado'
        }
    ];
    res.json({
        success: true,
        logs: logs,
        total: logs.length,
        note: 'Logs de sistema - Historial conversacional no incluido por privacidad'
    });
});

app.get('/health', (req, res) => {
    res.json({
        status: 'healthy',
        bot_active: botActive,
        model: process.env.GROQ_MODEL || 'mixtral-8x7b-32768',
        personality: 'Mancy - Terapeuta literaria existencialista',
        features: [
            'Wake-on-Message mejorado',
            'Historial conversacional',
            'Respuestas limpias de IA',
            'Modelo Groq avanzado',
            'Rate limiting activo'
        ],
        memory_usage: `${(process.memoryUsage().heapUsed / 1024 / 1024).toFixed(2)} MB`,
        uptime: `${(process.uptime() / 60).toFixed(1)} minutos`
    });
});

app.post('/wakeup', async (req, res) => {
    logger.info('üîî Wakeup recibido v√≠a POST');
    
    if (!botActive && !isStartingUp) {
        setTimeout(() => {
            startBot().catch(() => {
                logger.warn('Wakeup fall√≥ al iniciar');
            });
        }, 1000);
    }
    
    res.json({ 
        success: true, 
        message: 'Activando sistema Mancy...',
        bot_active: botActive,
        model: process.env.GROQ_MODEL || 'mixtral-8x7b-32768'
    });
});

// ========== INICIAR SERVIDOR ==========
const server = app.listen(PORT, '0.0.0.0', () => {
    console.log(`
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë         ü§ñ MANCY A.I PRO                 ‚ïë
‚ïë      üìö Sartre ‚Ä¢ Camus ‚Ä¢ Plath           ‚ïë
‚ïë      üß† Modelo: ${(process.env.GROQ_MODEL || 'mixtral-8x7b-32768').padEnd(18)}‚ïë
‚ïë                                          ‚ïë
‚ïë  Puerto: ${PORT.toString().padEnd(28)}‚ïë
‚ïë  URL: http://localhost:${PORT.toString().padEnd(21)}‚ïë
‚ïë  Status: ${botActive ? 'üü¢ Activo' : 'üü° Inactivo'.padEnd(26)}‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    `);
    
    // Sistema anti-suspensi√≥n para Render/Railway
    if (process.env.RENDER || process.env.RAILWAY) {
        logger.info('üîß Sistema anti-suspensi√≥n activado');
        
        keepAliveInterval = setInterval(async () => {
            try {
                const response = await fetch(`http://localhost:${PORT}/health`);
                if (response.ok) {
                    logger.info('üîÑ Ping autom√°tico exitoso');
                } else {
                    logger.warn('‚ö†Ô∏è Ping recibi√≥ respuesta no OK');
                }
            } catch (error) {
                logger.error('‚ùå Ping autom√°tico fall√≥:', error.message);
            }
        }, 240000); // Cada 4 minutos (m√°s eficiente)
        
        // Iniciar bot autom√°ticamente en hosting
        if (!botActive && !isStartingUp) {
            setTimeout(() => {
                startBot().catch(error => {
                    logger.error('Inicio autom√°tico fall√≥:', error.message);
                });
            }, 5000);
        }
    }
});

// ========== MANEJO DE APAGADO ==========
process.on('SIGTERM', () => {
    logger.info('üí§ Recibido SIGTERM - Apagando limpiamente...');
    
    // Limpiar intervalos
    if (keepAliveInterval) {
        clearInterval(keepAliveInterval);
    }
    
    // Desconectar Discord
    if (discordClient) {
        discordClient.destroy();
        logger.info('üëã Mancy desconectada de Discord');
    }
    
    // Cerrar servidor
    server.close(() => {
        logger.info('üåô Servidor HTTP cerrado');
        process.exit(0);
    });
    
    // Timeout de seguridad
    setTimeout(() => {
        logger.warn('‚ö†Ô∏è Forzando cierre por timeout');
        process.exit(1);
    }, 10000);
});

process.on('uncaughtException', (error) => {
    logger.error('‚ùå Excepci√≥n no capturada:', error);
});

process.on('unhandledRejection', (reason, promise) => {
    logger.error('‚ùå Promesa rechazada no manejada:', reason);
});

// ========== INFORMACI√ìN INICIAL ==========
logger.info('========================================');
logger.info('CONFIGURACI√ìN RECOMENDADA EN .env:');
logger.info('========================================');
logger.info('GROQ_MODEL=mixtral-8x7b-32768');
logger.info('# Opciones: llama-3.1-70b-versatile (mejor)');
logger.info('#           gemma2-9b-it (r√°pido)');
logger.info('#           llama-3.1-8b-instant (m√°s r√°pido)');
logger.info('========================================');
